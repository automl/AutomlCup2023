{
  "activation_ff": "gelu",
  "augmentation": "TrivialAugment",
  "dropout": 0.05375394085422158,
  "lr": 4.318458108100477e-05,
  "lr_scheduler": false,
  "max_epochs": 149,
  "model_name": "efn",
  "multi_dropout": false,
  "num_layers": 4,
  "optimizer": "AdamW",
  "pretrained": true,
  "starting_batch_size": 256,
  "use_ssl": false,
  "weight_decay": 0.024560393130812735
}